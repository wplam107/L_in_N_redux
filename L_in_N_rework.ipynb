{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling and Sentiment Analysis Rework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T21:48:40.847296Z",
     "start_time": "2020-05-29T21:48:40.840522Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import gensim\n",
    "\n",
    "from textblob import TextBlob\n",
    "from pprint import pprint\n",
    "from gensim import corpora, models\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "from topic_model import compute_coherence_values, plot_c_v, topics_in_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changes to the final project\n",
    "In the original \"the Language in News\" project dominant topic bias and  class imbalance possibly hindered potential insights.  In an attempt to improve topic coherence and clustering, various methods and changes will be employed, including:\n",
    "- Class imbalance will be dealt with by removing all South China Morning Post (SCMP) articles since it is the only local news source and produced various forms of bias in the data.\n",
    "- Certain features (i.e. sentiment scores of topics) will be scaled in order to help alleviate bias from dominant topics.\n",
    "- The entire articles will be used instead of the first 10 sentences.\n",
    "- Bigram model created across all articles instead of per article (incorrectly applied in the final project)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional cleaning of articles\n",
    "A script and functions were written to remove 'SCMP' articles, articles before the protests, unwanted articles.  A pickled DataFrame ```df_topic.p``` with additional preprocessing (tokenization, bigram creation, and lemmatization) is returned by running the ```prep_for_tm.py``` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T22:02:42.640013Z",
     "start_time": "2020-05-29T22:02:42.575988Z"
    }
   },
   "outputs": [],
   "source": [
    "# %run 'prep_for_tm.py'\n",
    "\n",
    "f = open('df_topic.p', 'rb')\n",
    "df = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T22:02:42.925111Z",
     "start_time": "2020-05-29T22:02:42.920057Z"
    }
   },
   "outputs": [],
   "source": [
    "# Text for topic modeling\n",
    "data = df['word_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T22:02:43.655986Z",
     "start_time": "2020-05-29T22:02:43.329143Z"
    }
   },
   "outputs": [],
   "source": [
    "id2word = corpora.Dictionary(data)\n",
    "id2word.filter_extremes(no_below=5, no_above=0.5, keep_n=10000)\n",
    "corpus = [ id2word.doc2bow(datum) for datum in data ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T19:42:57.208811Z",
     "start_time": "2020-05-29T19:42:57.206348Z"
    }
   },
   "outputs": [],
   "source": [
    "num_docs = len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-28T17:50:02.715376Z",
     "start_time": "2020-05-28T17:50:02.654179Z"
    }
   },
   "source": [
    "## Topic modeling\n",
    "Modeled on the collection of articles with standard LDA and LDA Mallet.  There local maxima for LDA and LDA Mallet coherence values at 3 topics (0.388 and  0.455, respectively) that had far greater interpretability than the possible global maxima at 12 and 19 topics.  The topics for LDA and LDA Mallet were manually labeled as economic, protests, political and protests, political, economic.  Ultimately the LDA Mallet model was chosen for its higher coherence values and less vocabulary overlap between topics.\n",
    "\n",
    "Additionally, the original project tried to assign a topic to individual sentences, however, after looking at topic probabilities, the model had difficulty determining which topic was most probable (most topic probabilities by sentence were between 30-40%).  Whereas the model was more capable of finding a most probable topic (often >50% for certain articles) when evaluating an entire article.\n",
    "\n",
    "Headlines did not appear to have much subjectivity or polarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T19:43:01.476081Z",
     "start_time": "2020-05-29T19:43:01.473534Z"
    }
   },
   "outputs": [],
   "source": [
    "mallet_path = '/Users/waynelam/Documents/DevStuff/mallet-2.0.8/bin/mallet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T20:12:34.423027Z",
     "start_time": "2020-05-29T20:01:00.825118Z"
    }
   },
   "outputs": [],
   "source": [
    "start, limit, step = 3, 20, 1\n",
    "model_list, coherence_values = compute_coherence_values(id2word,\n",
    "                                                        corpus,\n",
    "                                                        data,\n",
    "                                                        start=start,\n",
    "                                                        limit=limit,\n",
    "                                                        step=step,\n",
    "                                                        num_docs=num_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T20:12:34.609246Z",
     "start_time": "2020-05-29T20:12:34.426205Z"
    }
   },
   "outputs": [],
   "source": [
    "x = range(start, limit, step)\n",
    "plot_c_v(x, coherence_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T19:52:25.287175Z",
     "start_time": "2020-05-29T19:51:49.595646Z"
    }
   },
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       workers=6,\n",
    "                                       num_topics=3,\n",
    "                                       minimum_probability=0.75,\n",
    "                                       random_state=100,\n",
    "                                       chunksize=num_docs,\n",
    "                                       passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T19:52:25.296421Z",
     "start_time": "2020-05-29T19:52:25.290674Z"
    }
   },
   "outputs": [],
   "source": [
    "pprint(lda_model.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T19:52:31.247877Z",
     "start_time": "2020-05-29T19:52:25.298654Z"
    }
   },
   "outputs": [],
   "source": [
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))\n",
    "\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T20:25:09.469560Z",
     "start_time": "2020-05-29T20:12:34.612215Z"
    }
   },
   "outputs": [],
   "source": [
    "start, limit, step = 3, 20, 1\n",
    "model_list, coherence_values = compute_coherence_values(id2word,\n",
    "                                                        corpus,\n",
    "                                                        data,\n",
    "                                                        start=start,\n",
    "                                                        limit=limit,\n",
    "                                                        step=step,\n",
    "                                                        num_docs=num_docs,\n",
    "                                                        mallet_path=mallet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T20:25:09.644213Z",
     "start_time": "2020-05-29T20:25:09.472170Z"
    }
   },
   "outputs": [],
   "source": [
    "x = range(start, limit, step)\n",
    "plot_c_v(x, coherence_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T20:43:52.688107Z",
     "start_time": "2020-05-29T20:43:14.651169Z"
    }
   },
   "outputs": [],
   "source": [
    "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path,\n",
    "                                             corpus=corpus,\n",
    "                                             random_seed=100,\n",
    "                                             num_topics=3,\n",
    "                                             topic_threshold=0.75,\n",
    "                                             workers=6,\n",
    "                                             id2word=id2word)\n",
    "ldamallet.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T20:43:56.587873Z",
     "start_time": "2020-05-29T20:43:52.691004Z"
    }
   },
   "outputs": [],
   "source": [
    "coherence_model_ldamallet = CoherenceModel(model=ldamallet,\n",
    "                                           texts=data,\n",
    "                                           dictionary=id2word,\n",
    "                                           coherence='c_v')\n",
    "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_ldamallet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T20:43:56.596660Z",
     "start_time": "2020-05-29T20:43:56.591078Z"
    }
   },
   "outputs": [],
   "source": [
    "mallet_model = gensim.models.wrappers.ldamallet.malletmodel2ldamodel(ldamallet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T20:43:56.622755Z",
     "start_time": "2020-05-29T20:43:56.616250Z"
    }
   },
   "outputs": [],
   "source": [
    "# file = open('mallet.p', 'wb')      \n",
    "# pickle.dump(mallet_model, file)\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T21:57:22.015375Z",
     "start_time": "2020-05-29T21:57:22.005216Z"
    }
   },
   "outputs": [],
   "source": [
    "file = open('mallet.p', 'rb')\n",
    "mallet_model = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T22:02:50.015970Z",
     "start_time": "2020-05-29T22:02:49.621299Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['topics'] = df['word_tokens'].map(lambda x: topics_in_doc(x, id2word, mallet_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T22:02:50.054203Z",
     "start_time": "2020-05-29T22:02:50.042244Z"
    }
   },
   "outputs": [],
   "source": [
    "# Map topic probabilities to individual features\n",
    "df['protest'] = df['topics'].map(lambda x: x[0][1])\n",
    "df['political'] = df['topics'].map(lambda x: x[1][1])\n",
    "df['economic'] = df['topics'].map(lambda x: x[2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T22:02:57.897879Z",
     "start_time": "2020-05-29T22:02:52.031524Z"
    }
   },
   "outputs": [],
   "source": [
    "# Map polarity and subjectivity to individual features\n",
    "df['polarity'] = df['body'].map(lambda x: TextBlob(x).sentiment[0])\n",
    "df['subjectivity'] = df['body'].map(lambda x: TextBlob(x).sentiment[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T22:02:57.909274Z",
     "start_time": "2020-05-29T22:02:57.900261Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df[['headline', 'body', 'url', 'date', 'source', 'protest', 'political', 'economic', 'polarity', 'subjectivity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T22:25:43.496446Z",
     "start_time": "2020-05-29T22:25:43.449598Z"
    }
   },
   "outputs": [],
   "source": [
    "# file = open('df4cluster.p', 'wb')\n",
    "# pickle.dump(df, file)\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "redux_projects",
   "language": "python",
   "name": "redux_projects"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
